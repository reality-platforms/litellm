model_list:
  # OpenAI
  - model_name: gpt-4
    litellm_params:
      model: gpt-4
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-4-turbo
    litellm_params:
      model: gpt-4-turbo-preview
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-4o
    litellm_params:
      model: gpt-4o
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-4o-mini
    litellm_params:
      model: gpt-4o-mini
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: gpt-3.5-turbo
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
      
  # Fireworks AI
  - model_name: llama-3.1-8b
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
  - model_name: llama-3.1-70b
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
  - model_name: llama-3.3-70b
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
  - model_name: llama-3.2-11b-vision
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
  - model_name: llama-3.2-90b-vision
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
  - model_name: llama-3.1-405b
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
  - model_name: mixtral-8x22b
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
  # - model_name: whisper-v3
  #   litellm_params:
  #     model: fireworks_ai/accounts/fireworks/models/whisper-v3
  #     api_base: https://api.fireworks.ai/inference/v1
  #     api_key: os.environ/FIREWORKS_API_KEY
  #   model_info:
  #     mode: audio_transcription
  - model_name: WhereIsAI/UAE-Large-V1
    litellm_params:
      api_base: https://api.fireworks.ai/inference/v1
      model: fireworks_ai/WhereIsAI/UAE-Large-V1
      api_key: os.environ/FIREWORKS_API_KEY

  # Together AI
  - model_name: together/WhereIsAI/UAE-Large-V1
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/WhereIsAI/UAE-Large-V1
      api_key: os.environ/TOGETHER_API_KEY
  - model_name: together/llama-3.1-8b
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
  - model_name: together/llama-3.1-70b
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
  - model_name: together/llama-3.3-70b
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
  - model_name: together/llama-3.2-11b-vision
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
  - model_name: together/llama-3.2-90b-vision
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
  - model_name: together/llama-3.1-405b
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
  - model_name: together/mixtral-8x22b
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/mistralai/Mixtral-8x22B-Instruct-v0.1
      api_key: os.environ/TOGETHER_API_KEY
      
      

  # Groq AI
  # - model_name: groq/llama-3.1-8b-instant
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.1-8b-instant
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.1-70b-versatile
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.1-70b-versatile
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.2-11b-vision-preview
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.2-11b-vision-preview
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.2-90b-vision-preview
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.2-90b-vision-preview
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.3-70b-versatile
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.3-70b-versatile
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.1-405b-reasoning
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.1-405b-reasoning
  #     api_key: os.environ/GROQ_API_KEY


router_settings:
  fallbacks: [{"WhereIsAI/UAE-Large-V1":["together/WhereIsAI/UAE-Large-V1"]},{"llama-3.1-8b":["together/llama-3.1-8b"]},{"llama-3.1-70b":["together/llama-3.1-70b"]},{"llama-3.3-70b":["together/llama-3.3-70b"]},{"llama-3.2-11b-vision":["together/llama-3.2-11b-vision"]},{"llama-3.2-90b-vision":["together/llama-3.2-90b-vision"]},{"llama-3.1-405b":["together/llama-3.1-405b"]},{"mixtral-8x22b":["together/mixtral-8x22b"]}]


litellm_settings:
  # custom logging
  callbacks: custom_callbacks.proxy_handler_instance