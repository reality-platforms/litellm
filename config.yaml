model_list:
  # OpenAI
  - model_name: GPT_4
    litellm_params:
      model: gpt-4
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      mode: chat
  - model_name: GPT_4_turbo
    litellm_params:
      model: gpt-4-turbo-preview
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      mode: chat
  - model_name: GPT_4_o
    litellm_params:
      model: gpt-4o
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      mode: chat
  - model_name: GPT_4_o_mini
    litellm_params:
      model: gpt-4o-mini
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      mode: chat
  - model_name: GPT_3_5
    litellm_params:
      model: gpt-3.5-turbo
      custom_llm_provider: openai
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      mode: chat
      
  # Fireworks AI
  - model_name: LLAMA_3_1_8B
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
    model_info:
      mode: chat
  - model_name: LLAMA_3_1_70B
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
    model_info:
      mode: chat
  - model_name: LLAMA_3_3_70B
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
    model_info:
      mode: chat
  - model_name: LLAMA_3_2_11B_vision
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
    model_info:
      mode: chat
  - model_name: LLAMA_3_2_90B_vision
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
    model_info:
      mode: chat
  - model_name: LLAMA_3_1_405B
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
    model_info:
      mode: chat
  - model_name: MIXTRAL_8_22B
    litellm_params:
      model: fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct
      api_base: https://api.fireworks.ai/inference/v1
      api_key: os.environ/FIREWORKS_API_KEY
    model_info:
      mode: chat
  # - model_name: whisper-v3
  #   litellm_params:
  #     model: fireworks_ai/accounts/fireworks/models/whisper-v3
  #     api_base: https://api.fireworks.ai/inference/v1
  #     api_key: os.environ/FIREWORKS_API_KEY
  #   model_info:
  #     mode: audio_transcription
  - model_name: UAE_LARGE_V1
    litellm_params:
      api_base: https://api.fireworks.ai/inference/v1
      model: fireworks_ai/WhereIsAI/UAE-Large-V1
      api_key: os.environ/FIREWORKS_API_KEY
    model_info:
      mode: embedding

  # Together AI
  - model_name: together/UAE_LARGE_V1
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/WhereIsAI/UAE-Large-V1
      api_key: os.environ/TOGETHER_API_KEY
    model_info:
      mode: embedding
  - model_name: together/LLAMA_3_1_8B
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
    model_info:
      mode: chat
  - model_name: together/LLAMA_3_1_70B
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
    model_info:
      mode: chat
  - model_name: together/LLAMA_3_3_70B
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
    model_info:
      mode: chat
  - model_name: together/LLAMA_3_2_11B_vision
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
    model_info:
      mode: chat
  - model_name: together/LLAMA_3_2_90B_vision
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
    model_info:
      mode: chat
  - model_name: together/LLAMA_3_1_405B
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
    model_info:
      mode: chat
  - model_name: together/MIXTRAL_8_22B
    litellm_params:
      api_base: https://api.together.xyz/v1
      model: together_ai/mistralai/Mixtral-8x22B-Instruct-v0.1
      api_key: os.environ/TOGETHER_API_KEY
    model_info:
      mode: chat
      
      

  # Groq AI
  # - model_name: groq/llama-3.1-8b-instant
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.1-8b-instant
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.1-70b-versatile
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.1-70b-versatile
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.2-11b-vision-preview
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.2-11b-vision-preview
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.2-90b-vision-preview
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.2-90b-vision-preview
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.3-70b-versatile
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.3-70b-versatile
  #     api_key: os.environ/GROQ_API_KEY
  # - model_name: groq/llama-3.1-405b-reasoning
  #   litellm_params:
  #     custom_llm_provider: groq
  #     model: groq/llama-3.1-405b-reasoning
  #     api_key: os.environ/GROQ_API_KEY


router_settings:
  fallbacks: [{"UAE_LARGE_V1":["together/UAE_LARGE_V1"]},{"LLAMA_3_1_8B":["together/LLAMA_3_1_8B"]},{"LLAMA_3_1_70B":["together/LLAMA_3_1_70B"]},{"LLAMA_3_3_70B":["together/LLAMA_3_3_70B"]},{"LLAMA_3_2_11B_vision":["together/LLAMA_3_2_11B_vision"]},{"LLAMA_3_2_90B_vision":["together/LLAMA_3_2_90B_vision"]},{"LLAMA_3_1_405B":["together/LLAMA_3_1_405B"]},{"MIXTRAL_8_22B":["together/MIXTRAL_8_22B"]}]


litellm_settings:
  # custom logging
  callbacks: custom_callbacks.proxy_handler_instance
  drop_params: true
